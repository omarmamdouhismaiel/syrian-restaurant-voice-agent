import sys
import os
import streamlit as st
from datetime import datetime

# Add parent directory to import audio modules
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
from audio.asr import Transcriber
from audio.tts import TextToSpeech
from agent.voice_agent import detect_intent_and_entities

# Initialize components
transcriber = Transcriber()
tts = TextToSpeech()

st.set_page_config(page_title="Syrian Voice Agent", layout="centered")
st.title("ğŸ”Š Syrian Voice Agent UI")

# Session state initialization
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

if "last_audio_path" not in st.session_state:
    st.session_state.last_audio_path = None

if "input_pending" not in st.session_state:
    st.session_state.input_pending = False

# Input mode
input_mode = st.radio("Ø§Ø®ØªØ§Ø± Ø·Ø±ÙŠÙ‚Ø© Ø§Ù„Ø¥Ø¯Ø®Ø§Ù„", ["ğŸ“ Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ", "âŒ¨ï¸ ÙƒØªØ§Ø¨Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©"])
transcript = None

# Audio input
if input_mode == "ğŸ“ Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ":
    audio_file = st.file_uploader("Ø§Ø±ÙØ¹ Ù…Ù„Ù ØµÙˆØªÙŠ Ø¨ØµÙŠØºØ© WAV", type=["wav"])
    if audio_file and not st.session_state.input_pending:
        with open("temp.wav", "wb") as f:
            f.write(audio_file.read())
        transcript = transcriber.transcribe_audio("temp.wav")
        if transcript:
            st.success("âœ… ØªÙ… ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ø¥Ù„Ù‰ Ù†Øµ")
            st.write("ğŸ“ Ø§Ù„Ù†Øµ Ø§Ù„Ù…ÙƒØªÙˆØ¨:", transcript)
            st.session_state.input_pending = True
        else:
            st.error("âŒ ÙØ´Ù„ ÙÙŠ Ø§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù…")

# Text input
elif input_mode == "âŒ¨ï¸ ÙƒØªØ§Ø¨Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©":
    transcript_input = st.text_input("âœï¸ Ø§ÙƒØªØ¨ Ø¬Ù…Ù„Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©", key="text_input")
    if transcript_input and not st.session_state.input_pending:
        transcript = transcript_input
        st.session_state.input_pending = True

# Process input
if st.session_state.input_pending and not st.session_state.last_audio_path:
    transcript = transcript or transcript_input
    intent, entities = detect_intent_and_entities(transcript)

    # Response logic
    if intent == "ask_name":
        response_text = "Ø£Ù†Ø§ Ù…Ø³Ø§Ø¹Ø¯ ØµÙˆØªÙŠ Ø³ÙˆØ±ÙŠ."
    elif intent == "ask_time":
        response_text = f"Ø§Ù„Ø³Ø§Ø¹Ø© Ø§Ù„Ø¢Ù† {datetime.now().strftime('%H:%M')}."
    elif intent == "order_food" and entities.get("items"):
        items_str = " Ùˆ ".join(entities["items"])
        response_text = f"ØªÙ… ØªØ³Ø¬ÙŠÙ„ Ø·Ù„Ø¨Ùƒ: {items_str}."
    else:
        response_text = "Ù„Ù… Ø£ÙÙ‡Ù… Ù‚ØµØ¯ÙƒØŒ Ù‡Ù„ ÙŠÙ…ÙƒÙ†Ùƒ Ø§Ù„ØªÙˆØ¶ÙŠØ­ØŸ"

    # Save to chat history
    st.session_state.chat_history.append((transcript, response_text))

    # Generate audio
    with st.spinner("ğŸ”Š ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ø±Ø¯ ØµÙˆØªÙŠÙ‹Ø§..."):
        audio_path = tts.generate(response_text)
        if os.path.exists(audio_path):
            st.session_state.last_audio_path = audio_path
        else:
            st.error("âŒ Ù„Ù… ÙŠØªÙ… ØªÙˆÙ„ÙŠØ¯ Ø§Ù„Ù…Ù„Ù Ø§Ù„ØµÙˆØªÙŠ")

# Chat history
if st.session_state.chat_history:
    st.markdown("### ğŸ’¬ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©")
    for user_msg, bot_msg in st.session_state.chat_history:
        st.markdown(f"**ğŸ§‘â€ğŸ¦± Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…:** {user_msg}")
        st.markdown(f"**ğŸ¤– Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯:** {bot_msg}")

# Play audio and reset input state
if st.session_state.last_audio_path:
    st.audio(st.session_state.last_audio_path, format="audio/mp3")
    if st.button("ğŸ‘‚ Ø§Ø³ØªÙ…Ø¹ ÙˆØ£Ø±Ø³Ù„ Ø±Ø³Ø§Ù„Ø© Ø¬Ø¯ÙŠØ¯Ø©"):
        st.session_state.last_audio_path = None
        st.session_state.input_pending = False
        st.rerun()

# Reset button
st.sidebar.markdown("---")
if st.sidebar.button("ğŸ§¹ Ø¥Ø¹Ø§Ø¯Ø© ØªØ¹ÙŠÙŠÙ† Ø§Ù„Ù…Ø­Ø§Ø¯Ø«Ø©"):
    st.session_state.chat_history = []
    st.session_state.last_audio_path = None
    st.session_state.input_pending = False
    st.rerun()
